{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libSM.so.6: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d7f443b0c052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mYOLO\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlabel_map\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-00/06/206/j1burke/ECE285/ECE285_Sauvage_Object_Detection/YOLO/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mYOLO\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-00/06/206/j1burke/ECE285/ECE285_Sauvage_Object_Detection/YOLO/bbox.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconfidence_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/cv2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libSM.so.6: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from YOLO import *\n",
    "from label_map import *\n",
    "from data.util import read_image\n",
    "from utils.vis_tool import vis_bbox\n",
    "from utils import array_tool as at\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PascalVOCDataloader import PascalVOCDataloader, create_split_loaders\n",
    "data_dir = '/datasets/ee285f-public/PascalVOC2012/'\n",
    "model_dir = 'YOLO/cfg/'\n",
    "test_file = 'YOLO_Pretrained'\n",
    "\n",
    "# Load Dataset\n",
    "dataset = PascalVOCDataloader(data_dir, normalize=True, YOLO=True)\n",
    "train_loader, val_loader, test_loader = create_split_loaders(dataset,batch_size=1)\n",
    "\n",
    "# Load Model\n",
    "#faster_rcnn = FasterRCNNVGG16()\n",
    "yolo = Darknet(\"YOLO/cfg/yolov3.cfg\")\n",
    "yolo.load_weights(\"YOLO/yolov3.weights\")\n",
    "#trainer = FasterRCNNTrainer(faster_rcnn).cuda()\n",
    "#trainer.load(model_dir+'fasterrcnn_12211511_0.701052458187_torchvision_pretrain')\n",
    "img, q, e = next(iter(val_loader))\n",
    "\n",
    "det = yolo(img, CUDA=False)\n",
    "\n",
    "op = write_results(det,0.5,80,0.4)\n",
    "_bboxes = op[:,1:5]\n",
    "_labels = op[:,-1]\n",
    "_scores = op[:,-2]\n",
    "print(_bboxes)\n",
    "#_bboxes, _labels, _scores = trainer.faster_rcnn.predict(img,visualize=False, score_thresh=0.7)\n",
    "vis_bbox(at.tonumpy(img[0]),\n",
    "         at.tonumpy(_bboxes),\n",
    "         at.tonumpy(_labels).reshape(-1),\n",
    "         at.tonumpy(_scores).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = write_results(det,0.5,80,0.4)\n",
    "print(op.shape)\n",
    "print(_bboxes)\n",
    "print(det.shape)\n",
    "_bboxes = op[:,1:5]\n",
    "_labels = op[:,-1]\n",
    "_scores = op[:,-2]\n",
    "for idx,l in enumerate(pred_labels):\n",
    "    _labels[idx] = coco_to_pascal[l]\n",
    "print(_labels.shape, _bboxes.shape, _scores.shape)\n",
    "vis_bbox(at.tonumpy(img[0]),\n",
    "         at.tonumpy(_bboxes),\n",
    "         at.tonumpy(_labels).reshape(-1),\n",
    "         at.tonumpy(_scores).reshape(-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Save Testing Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "n_classes = 20\n",
    "class_labels = [ 1, 5, 6, 7, 9, 11, 12, 13, 14, 16, 18]\n",
    "\n",
    "### Load Results into Dataframe ###\n",
    "PRED_COL = ['img_num', 'pred_bboxes', 'pred_labels', 'pred_scores']\n",
    "Predicted_Data = pd.DataFrame(columns=PRED_COL)\n",
    "TRUE_COL = ['img_num', 'true_bboxes', 'true_labels']\n",
    "True_Data = pd.DataFrame(columns=TRUE_COL)\n",
    "n_pred_bboxes = 0\n",
    "n_pred_thresh = 10\n",
    "class_check = np.zeros((n_classes))\n",
    "import time\n",
    "\n",
    "\n",
    "for img_num, (img, true_bboxes, true_labels) in enumerate(test_loader, 0):\n",
    "    true_bboxes, true_labels, = true_bboxes.numpy()[0], true_labels.numpy()[0]\n",
    "    start_time = time.time()\n",
    "    det = yolo(img, CUDA=False)\n",
    "    output = write_results(det,0.5,80,0.4)\n",
    "    print('Epoch', start_time - time.time())\n",
    "    pred_bboxes = output[:,1:5]\n",
    "    pred_labels = output[:,-1]\n",
    "    pred_scores = output[:,-2]\n",
    "    \n",
    "    for idx,l in enumerate(pred_labels):\n",
    "        pred_labels[idx] = coco_to_pascal[l]\n",
    "    \n",
    "    #pred_bboxes, pred_labels, pred_scores = trainer.faster_rcnn.predict(img,visualize=False, score_thresh=0.45) # YOLO model pred\n",
    "    pred_bboxes, pred_labels, pred_scores = np.asarray(pred_bboxes)[0], np.asarray(pred_labels)[0], np.asarray(pred_scores)[0]\n",
    "    print(pred_bboxes.shape)\n",
    "    n_pred = pred_bboxes.shape[0]\n",
    "    for i in range(n_pred):\n",
    "        tmp_df = pd.DataFrame([[img_num, pred_bboxes[i], pred_labels[i], pred_scores[i]]], columns=PRED_COL) # COCO to PAs\n",
    "        Predicted_Data = Predicted_Data.append(tmp_df, ignore_index=True)\n",
    "    n_true = true_bboxes.shape[0]\n",
    "    for i in range(n_true):\n",
    "        tmp_df = pd.DataFrame([[img_num, true_bboxes[i], true_labels[i]]], columns=TRUE_COL)\n",
    "        True_Data = True_Data.append(tmp_df, ignore_index=True)\n",
    "        class_check[true_labels[i]] = 1\n",
    "    n_pred_bboxes += pred_bboxes.shape[0]\n",
    "    cc = class_check[class_labels]\n",
    "    print(np.sum(cc))\n",
    "    if (n_pred_bboxes > n_pred_thresh and (np.sum(cc) == len(class_labels))):\n",
    "        print('Test conditions reached with %d test images and %d predicted boxes' % (img_num, n_pred_bboxes))\n",
    "        break\n",
    "\n",
    "#Predicted_Data.to_pickle(test_file+'_Predicted_Data.pkl')\n",
    "#True_Data.to_pickle(test_file+'_True_Data.pkl')\n",
    "print(Predicted_Data.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IoU import bb_intersection_over_union\n",
    "Predicted_Data = pd.read_pickle(test_file+'_Predicted_Data.pkl')\n",
    "#print(Predicted_Data)\n",
    "True_Data = pd.read_pickle(test_file+'_True_Data.pkl')\n",
    "#True_Data.to_pickle('RCNN_True_Data.pkl')\n",
    "Predicted_Data.sort_values(['pred_scores'], axis=0, ascending=False, inplace=True)\n",
    "Predicted_Data.reset_index(inplace=True)\n",
    "#print(Predicted_Data[:4])\n",
    "#print(True_Data['true_labels'].value_counts())\n",
    "    \n",
    "\n",
    "def calc_precision_recall(Predicted_Data, True_Data, class_labels):\n",
    "    Predicted_Data = Predicted_Data.sort_values(['pred_scores'], axis=0, ascending=False, inplace=False)\n",
    "    Predicted_Data = Predicted_Data.reset_index(inplace=False)\n",
    "    n_classes = len(class_labels)\n",
    "    mAP_thresh = 0.5\n",
    "    \n",
    "    n_pred = Predicted_Data.shape[0]\n",
    "    Precision = np.zeros((n_pred))\n",
    "    Recall = np.zeros((n_pred))\n",
    "    TP_FN = True_Data['true_labels'].value_counts()\n",
    "    n_pred = 100\n",
    "    for p in range(1,n_pred+1):\n",
    "        pred_data = Predicted_Data[:p]\n",
    "        class_precision = []\n",
    "        class_recall = []\n",
    "        for c in range(n_classes):\n",
    "            if  not(TP_FN.keys().contains(c)):\n",
    "                continue\n",
    "            cl = class_labels[c]\n",
    "            pred_data_cl = pred_data.loc[pred_data['pred_labels'] == cl]\n",
    "            n_bboxes = pred_data_cl.shape[0]\n",
    "            TP = 0\n",
    "            FP = 0\n",
    "            # Check if positives are True or False\n",
    "            for _,pred_row in pred_data_cl.iterrows():\n",
    "                pred_bbox = pred_row['pred_bboxes']\n",
    "                img_num = pred_row['img_num']\n",
    "                true_data = True_Data.loc[True_Data['img_num'] == img_num]\n",
    "                true_data = true_data.loc[true_data['true_labels'] == cl]\n",
    "                n_true_bboxes = true_data.shape[0]\n",
    "                # Calculate iou between ground truth and predictions\n",
    "                max_iou = 0\n",
    "                for _,true_row in true_data.iterrows():\n",
    "                    true_bbox = true_row['true_bboxes']\n",
    "                    print(pred_bbox)\n",
    "                    print(img_num, true_bbox)\n",
    "                    iou = bb_intersection_over_union(pred_bbox, true_bbox)\n",
    "                    if (iou > max_iou):\n",
    "                        max_iou = iou\n",
    "                if (max_iou >= mAP_thresh):\n",
    "                    TP += 1\n",
    "                elif (max_iou < mAP_thresh):\n",
    "                    FP += 1\n",
    "            if (n_bboxes > 0):\n",
    "                class_precision.append(TP/(TP+FP))\n",
    "                class_recall.append(TP/TP_FN[cl])\n",
    "        if(len(class_precision) > 0):\n",
    "            Precision[p-1] = sum(class_precision)/len(class_precision)\n",
    "            Recall[p-1] = sum(class_recall)/len(class_recall)\n",
    "\n",
    "    return Precision, Recall\n",
    "\n",
    "Precision, Recall = calc_precision_recall(Predicted_Data, True_Data, class_labels)\n",
    "np.save(test_file+'_Precision.npy', Precision) \n",
    "np.save(test_file+'_Recall.npy', Recall)\n",
    "#TP_FN = True_Data['true_labels'].value_counts()\n",
    "#print(type(TP_FN), TP_FN.keys().contains(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Total PR Curve and Calculate mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision = np.load(test_file+'_Precision.npy') \n",
    "Recall = np.load(test_file+'_Recall.npy')\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(Recall, Precision, '.')\n",
    "#print(Precision, Recall)\n",
    "def calculate_mAP(Recall, Precision):\n",
    "    N = Precision.shape[0]\n",
    "    # Smooth precision curve\n",
    "    for i in range(N-1):\n",
    "        ind_right = (Recall >= Recall[i])\n",
    "        Precision[i] = max(Precision[i], np.max(Precision[ind_right]))\n",
    "    # Interpolate PR values\n",
    "    recall_steps = np.linspace(0,1,11)\n",
    "    Interp_Precision = np.zeros(11)\n",
    "    for i in range(11):\n",
    "        r = recall_steps[i]\n",
    "        ind_closest = np.argmin(np.absolute(r - Recall))\n",
    "        if (np.absolute(Recall[ind_closest] - r) <= 0.1):\n",
    "            Interp_Precision[i] = Precision[ind_closest]\n",
    "            Recall[ind_closest] = 0\n",
    "    mAP = np.sum(Interp_Precision)/11\n",
    "    return mAP\n",
    "\n",
    "mAP = calculate_mAP(Recall, Precision)\n",
    "print(mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Class Specific PR Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "Predicted_Data = pd.read_pickle(test_file+'_Predicted_Data.pkl')\n",
    "True_Data = pd.read_pickle(test_file+'_True_Data.pkl')\n",
    "\n",
    "\n",
    "classes = {0:'Aeroplane', 1:'Bicycle',2:'Bird',3:'Boat',4:'Bottle',5:'Bus',\n",
    "                        6:'Car', 7:'Cat',8:'Chair',9:'Cow',10:'Diningtable',11:'Dog',\n",
    "                        12:'Horse', 13:'Motorbike',14:'Person',15:'Potted Plant',\n",
    "                        16:'Sheep', 17:'Sofa',18:'Train',19:'Tv Monitor'}\n",
    "# Plot Precision Recall for each class\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(16)\n",
    "fig.set_figwidth(20)\n",
    "for c in class_labels:\n",
    "    P,R = calc_precision_recall(Predicted_Data, True_Data, [c])\n",
    "    plt.subplot(5, 4, c+1)\n",
    "    plt.plot(R, P, '.')\n",
    "    plt.xlabel('Recall',fontsize=16)\n",
    "    plt.ylabel('Precision',fontsize=16)\n",
    "    plt.title(' Class = '+ classes[c],fontsize=20)\n",
    "    plt.rc('xtick',labelsize=14)\n",
    "    plt.rc('ytick',labelsize=14)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('plot/'+test_file+'_Class_PR.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
